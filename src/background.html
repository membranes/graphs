<!doctype html>
<html lang="en">
	<head>

		<meta charset="utf-8" />
		<link rel="icon" href="/assets/images/favicon.png" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />

		<link href="../assets/css/module/0.Dr8j8DIg.css" rel="stylesheet">
		<link href="../assets/css/module/4.C4MfQ6Mv.css" rel="stylesheet">
		<link href="../assets/css/tooltips.css" rel="stylesheet">

		<script src="../assets/js/module/latex.js" async></script>

		<title>BACKGROUND</title>

	</head>
	<body data-sveltekit-preload-data="hover">

		<div style="display: contents">

			<div class="layout">

				<div class="layout-head">
					<h1>$\xi$</h1>
				</div>
				<div class="layout-reference">
					PRODUCT INTERFACE<br>
					<span class="tooltip">AIR <span class="tooltiptext">Artificial Intelligence Register</span></span><br>
					<div id="stamp"></div>
				</div>

				<div class="layout-item">

					<div class="frames-grid-left svelte-1jxvby2">
						<a href="../index.html">home</a><br>
						<a href="background.html">about</a><br>
						<a href="./frames.html">frames</a>
					</div>

				</div>

				<div class="layout-item">

					<div class="frames-grid-item svelte-1jxvby2">
						<h3>Background</h3>
						At present, teams across the United Kingdom's governments <b>manually identify or detect words/strings</b> of interest within documents <b>for</b> redaction, knowledge graph, criminal investigations, etc., purposes.  In the case of redaction, a few teams have access to standard solutions, i.e., software solutions focused on detecting and/or redacting common <a href='https://www.legislation.gov.uk/eur/2016/679/article/4' target='_blank'>personal data</a> words/strings.  Alas, these solutions do not address the needs of teams that need to identify or detect bespoke words/strings.<br><br>A viable approach involves the creation of custom models via <i>named entity recognition</i> machine learning algorithms.  These algorithms can be trained by domain, leading to compact, domain specific, word/string detection models. These algorithms are also known as token classification algorithms.

						This project focuses on a single token classification problem.  The fundamentals page outlines the project's

						<ul><li>Problem Statement</li><li>Outcome Expectations/Underlying Aims</li><li>Deployment Goal</li></ul>

						The pages there after outline further project/model details.

					</div>

				</div>

			</div>

		</div>

		<script type="module">
			import {stamp} from '../assets/js/module/latest.js'
			document.getElementById("stamp").innerHTML = stamp();
		</script>

	</body>

</html>
